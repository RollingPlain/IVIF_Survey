# IVIF Survey: DacTa
Infrared and Visible Image Fusion: From Data Compatibility to Task Adaption
# 我的项目

## 访问统计
![访客统计](https://visitor-badge.glitch.me/badge?page_id=RollingPlain.IVIF_Survey)
![点击统计](https://img.shields.io/badge/dynamic/json?label=访问次数&query=value&url=https://api.countapi.xyz/hit/RollingPlain/IVIF_Surveyy)

## Star 数量
![GitHub stars](https://img.shields.io/github/stars/RollingPlain/IVIF_Survey?style=social)


# Available Data
# 红外和可见光图像融合(Infrared and visible image fusion)

| 方法名 | 标题 | 论文链接 | 代码链接 | 发表期刊 | 发表年份 |
| --- | --- | --- | --- | --- | --- |
| AUIF | Efficient and model-based infrared and visible image fusion via algorithm unrolling | [Paper](https://ieeexplore.ieee.org/abstract/document/9416456) | [Code](https://github.com/Zhaozixiang1228/IVIF-AUIF-Net) | TCSVT | 2021 |
| AtFGAN | Attentionfgan: Infrared and visible image fusion using attention-based generative adversarial networks | [Paper](https://ieeexplore.ieee.org/abstract/document/9103116) |  | TMM | 2020 |
| BDLFusion | Bi-level dynamic learning for jointly multi-modality image fusion and beyond | [Paper](https://arxiv.org/abs/2305.06720) | [Code](https://github.com/LiuZhu-CV/BDLFusion) | IJCAI | 2023 |
| BIMDL | A bilevel integrated model with data-driven layer ensemble for multi-modality image fusion | [Paper](https://ieeexplore.ieee.org/abstract/document/9293146) |  | TIP | 2020 |
| CAF | Where elegance meets precision: Towards a compact, automatic, and flexible framework for multi-modality image fusion and applications | [Paper](https://www.ijcai.org/proceedings/2024/0123.pdf) | [Code](https://github.com/RollingPlain/CAF_IVIF) | IJCAI | 2024 |
| CDDFuse | Cddfuse: Correlation-driven dual-branch feature decomposition for multi-modality image fusion | [Paper](https://openaccess.thecvf.com/content/CVPR2023/html/Zhao_CDDFuse_Correlation-Driven_Dual-Branch_Feature_Decomposition_for_Multi-Modality_Image_Fusion_CVPR_2023_paper.html) | [Code](https://github.com/Zhaozixiang1228/MMIF-CDDFuse) | CVPR | 2023 |
| CMTFusion | Cross-modal transformers for infrared and visible image fusion | [Paper](https://ieeexplore.ieee.org/abstract/document/10163247) | [Code](https://github.com/seonghyun0108/CMTFusion) | TCSVT | 2023 |
| CUFD | Cufd: An encoder–decoder network for visible and infrared image fusion based on common and unique feature decomposition | [Paper](https://www.sciencedirect.com/science/article/abs/pii/S1077314222000352) | [Code](https://github.com/Meiqi-Gong/CUFD) | CVIU | 2022 |
| CoCoNet | Coconet: Coupled contrastive learning network with multi-level feature ensemble for multi-modality image fusion | [Paper](https://link.springer.com/article/10.1007/s11263-023-01952-1) | [Code](https://github.com/runjia0124/CoCoNet) | IJCV | 2023 |
| D2WGAN | Infrared and visible image fusion using dual discriminators generative adversarial networks with wasserstein distance | [Paper](https://www.sciencedirect.com/science/article/abs/pii/S0020025520303431) |  | InfSci | 2020 |
| DDFM | Ddfm: denoising diffusion model for multi-modality image fusion | [Paper](https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_DDFM_Denoising_Diffusion_Model_for_Multi-Modality_Image_Fusion_ICCV_2023_paper.html) | [Code](https://github.com/Zhaozixiang1228/MMIF-DDFM) | ICCV | 2023 |
| DDcGAN | Learning a generative model for fusing infrared and visible images via conditional generative adversarial network with dual discriminators | [Paper](https://www.ijcai.org/proceedings/2019/0549.pdf) | [Code](https://github.com/hanna-xu/DDcGAN) | TIP | 2019 |
| DIDFuse | Didfuse: Deep image decomposition for infrared and visible image fusion | [Paper](https://arxiv.org/abs/2003.09210) | [Code](https://github.com/Zhaozixiang1228/IVIF-DIDFuse) | IJCAI | 2020 |
| DPAL | Infrared and visible image fusion via detail preserving adversarial learning | [Paper](https://www.sciencedirect.com/science/article/abs/pii/S1566253519300314) | [Code](https://github.com/StaRainJ/ResNetFusion) | InfFus | 2020 |
| DenseFuse | Densefuse: A fusion approach to infrared and visible images | [Paper](https://ieeexplore.ieee.org/abstract/document/8580578/) | [Code](https://github.com/hli1221/imagefusion_densefuse) | TIP | 2018 |
| DetFusion | Detfusion: A detection-driven infrared and visible image fusion network | [Paper](https://dl.acm.org/doi/abs/10.1145/3503161.3547902) | [Code](https://github.com/SunYM2020/DetFusion) | ACMMM | 2022 |
| Dif-Fusion | Dif-fusion: Towards high color fidelity in infrared and visible image fusion with diffusion models | [Paper](https://ieeexplore.ieee.org/abstract/document/10286359/) | [Code](https://github.com/GeoVectorMatrix/Dif-Fusion) | TIP | 2023 |
| EMMA | Equivariant multi-modality image fusion | [Paper](https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_Equivariant_Multi-Modality_Image_Fusion_CVPR_2024_paper.html) | [Code](https://github.com/Zhaozixiang1228/MMIF-EMMA) | CVPR | 2024 |
| FILM | Image fusion via vision-language model | [Paper](https://arxiv.org/abs/2402.02235) | [Code](https://github.com/Zhaozixiang1228/IF-FILM) | ICML | 2024 |
| FreqGAN | Freqgan: Infrared and visible image fusion via unified frequency adversarial learning | [Paper](https://ieeexplore.ieee.org/abstract/document/10680110/) | [Code](https://github.com/Zhishe-Wang/FreqGAN) | TCSVT | 2024 |
| FusionDN | Fusiondn: A unified densely connected network for image fusion | [Paper](https://aaai.org/ojs/index.php/AAAI/article/view/6936) | [Code](https://github.com/hanna-xu/FusionDN) | AAAI | 2020 |
| FusionGAN | Fusiongan: A generative adversarial network for infrared and visible image fusion | [Paper](https://www.sciencedirect.com/science/article/pii/S1566253518301143) | [Code](https://github.com/jiayi-ma/FusionGAN) | InfFus | 2019 |
| GANMcC | Ganmcc: A generative adversarial network with multiclassification constraints for infrared and visible image fusion | [Paper](https://ieeexplore.ieee.org/abstract/document/9274337/) | [Code](https://github.com/HaoZhang1018/GANMcC) | TIM | 2020 |
| GCRF | General cross-modality registration framework for visible and infrared UAV target image registration | [Paper](https://www.nature.com/articles/s41598-023-39863-3) |  | SR | 2023 |
| ICAFusion | Infrared and visible image fusion via interactive compensatory attention adversarial learning | [Paper](https://ieeexplore.ieee.org/abstract/document/9982426/) | [Code](https://github.com/Zhishe-Wang/ICAFusion) | TMM | 2022 |
| IFCNN | Ifcnn: A general image fusion framework based on convolutional neural network | [Paper](https://www.sciencedirect.com/science/article/pii/S1566253518305505) | [Code](https://github.com/uzeful/IFCNN) | InfFus | 2020 |
| IFT | Image fusion transformer | [Paper](https://ieeexplore.ieee.org/abstract/document/9897280/) | [Code](https://github.com/Vibashan/Image-Fusion-Transformer) | ICIP | 2022 |
| IGNet | Learning a graph neural network with cross modality interaction for image fusion | [Paper](https://dl.acm.org/doi/abs/10.1145/3581783.3612135) | [Code](https://github.com/lok-18/IGNet) | ACMMM | 2023 |
| IRFS | An interactively reinforced paradigm for joint infrared-visible image fusion and saliency object detection | [Paper](https://www.sciencedirect.com/science/article/pii/S1566253523001446) | [Code](https://github.com/wdhudiekou/IRFS) | InfFus | 2023 |
| LRRNet | Lrrnet: A novel representation learning guided fusion network for infrared and visible images | [Paper](https://ieeexplore.ieee.org/abstract/document/10105495/) | [Code](https://github.com/hli1221/imagefusion-LRRNet) | TPAMI | 2023 |
| MFEIF | Learning a deep multi-scale feature ensemble and an edge-attention guidance for image fusion | [Paper](https://ieeexplore.ieee.org/abstract/document/9349250) | [Code](https://github.com/JinyuanLiu-CV/MFEIF) | TCSVT | 2021 |
| MRFS | Mrfs: Mutually reinforcing image fusion and segmentation | [Paper](https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_MRFS_Mutually_Reinforcing_Image_Fusion_and_Segmentation_CVPR_2024_paper.html) | [Code](https://github.com/HaoZhang1018/MRFS) | CVPR | 2024 |
| MURF | MURF: mutually reinforcing multi-modal image registration and fusion | [Paper](https://ieeexplore.ieee.org/abstract/document/10145843) | [Code](https://github.com/hanna-xu/MURF) | TPAMI | 2023 |
| MetaFusion | Metafusion: Infrared and visible image fusion via meta-feature embedding from object detection | [Paper](https://openaccess.thecvf.com/content/CVPR2023/html/Zhao_MetaFusion_Infrared_and_Visible_Image_Fusion_via_Meta-Feature_Embedding_From_CVPR_2023_paper.html) | [Code](https://github.com/wdzhao123/MetaFusion) | CVPR | 2023 |
| MgAN-Fuse | Multigrained attention network for infrared and visible image fusion | [Paper](https://ieeexplore.ieee.org/abstract/document/9216075) |  | TIM | 2020 |
| MoE-Fusion | Multi-modal gated mixture of local-to-global experts for dynamic image fusion | [Paper](https://openaccess.thecvf.com/content/ICCV2023/html/Cao_Multi-Modal_Gated_Mixture_of_Local-to-Global_Experts_for_Dynamic_Image_Fusion_ICCV_2023_paper.html) | [Code](https://github.com/SunYM2020/MoE-Fusion) | ICCV | 2023 |
| PAIFusion | Paif: Perceptionaware infrared-visible image fusion for attack-tolerant semantic segmentation | [Paper](https://dl.acm.org/doi/abs/10.1145/3581783.3611928) | [Code](https://github.com/LiuZhu-CV/PAIF) | ACMMM | 2023 |
| PMGI | Rethinking the image fusion: A fast unified image fusion network based on proportional maintenance of gradient and intensity | [Paper](https://ojs.aaai.org/index.php/AAAI/article/view/6975) | [Code](https://github.com/HaoZhang1018/PMGI_AAAI2020) | AAAI | 2020 |
| PSFusion | Rethinking the necessity of image fusion in high-level vision tasks: A practical infrared and visible image fusion network based on progressive semantic injection and scene fidelity | [Paper](https://www.sciencedirect.com/science/article/pii/S1566253523001860) | [Code](https://github.com/Linfeng-Tang/PSFusion) | InfFus | 2032 |
| PromptF | Promptfusion: Harmonized semantic prompt learning for infrared and visible image fusion |  |  | JAS | 2024 |
| RFN-Nest | Rfn-nest: An end-to-end residual fusion network for infrared and visible images | [Paper](https://www.sciencedirect.com/science/article/pii/S1566253521000440) | [Code](https://github.com/hli1221/imagefusion-rfn-nest) | TIM | 2021 |
| RXDNFuse | Rxdnfuse: A aggregated residual dense network for infrared and visible image fusion | [Paper](https://www.sciencedirect.com/science/article/pii/S1566253520304152) |  | InfFus | 2021 |
| Re2Fusion | Res2fusion: Infrared and visible image fusion based on dense res2net and double nonlocal attention models | [Paper](https://ieeexplore.ieee.org/abstract/document/9670874) | [Code](https://github.com/Zhishe-Wang/Res2Fusion) | TIM | 2022 |
| ReCoNet | Reconet: Recurrent correction network for fast and efficient multi-modality image fusion | [Paper](https://link.springer.com/chapter/10.1007/978-3-031-19797-0_31) | [Code](https://github.com/dlut-dimt/ReCoNet) | ECCV | 2022 |
| SDNet | Sdnet: A versatile squeeze-and-decomposition network for real-time image fusion | [Paper](https://link.springer.com/article/10.1007/s11263-021-01501-8) | [Code](https://github.com/HaoZhang1018/SDNet) | IJCV | 2021 |
| SEDRFuse | Sedrfuse: A symmetric encoder–decoder with residual block network for infrared and visible image fusion | [Paper](https://ieeexplore.ieee.org/abstract/document/9187663) | [Code](https://github.com/jianlihua123/SEDRFuse) | TIM | 2020 |
| SFAFuse | Self-supervised feature adaption for infrared and visible image fusion | [Paper](https://www.sciencedirect.com/science/article/pii/S1566253521001287) | [Code](https://github.com/zhoafan/SFA-Fuse) | InfFus | 2021 |
| SMoA | Smoa: Searching a modality-oriented architecture for infrared and visible image fusion | [Paper](https://ieeexplore.ieee.org/abstract/document/9528046) | [Code](https://github.com/JinyuanLiu-CV/SMoA) | SPL | 2021 |
| STDFusionNet | Stdfusionnet: An infrared and visible image fusion network based on salient target detection | [Paper](https://ieeexplore.ieee.org/abstract/document/9416507) | [Code](https://github.com/jiayi-ma/STDFusionNet) | TIM | 2021 |
| SeAFusion | Image fusion in the loop of high-level vision tasks: A semantic-aware real-time infrared and visible image fusion network | [Paper](https://www.sciencedirect.com/science/article/pii/S1566253521002542) | [Code](https://github.com/Linfeng-Tang/SeAFusion) | InfFus | 2022 |
| SegMiF | Multi-interactive feature learning and a full-time multimodality benchmark for image fusion and segmentation | [Paper](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Multi-interactive_Feature_Learning_and_a_Full-time_Multi-modality_Benchmark_for_Image_ICCV_2023_paper.html) | [Code](https://github.com/JinyuanLiu-CV/SegMiF) | ICCV | 2023 |
| SemLA | Semantics lead all: Towards unified image registration and fusion from a semantic perspective | [Paper](https://www.sciencedirect.com/science/article/pii/S1566253523001513) | [Code](https://github.com/xiehousheng/SemLA) | InfFus | 2023 |
| SuperFusion | Superfusion: A versatile image registration and fusion network with semantic awareness | [Paper](https://ieeexplore.ieee.org/abstract/document/9970457) | [Code](https://github.com/Linfeng-Tang/SuperFusion) | JAS | 2022 |
| SwinFusion | Swinfusion: Cross-domain long-range learning for general image fusion via swin transformer | [Paper](https://ieeexplore.ieee.org/abstract/document/9812535) | [Code](https://github.com/Linfeng-Tang/SwinFusion) | JAS | 2022 |
| TCGAN | Transformer based conditional gan for multimodal image fusion | [Paper](https://ieeexplore.ieee.org/abstract/document/10041783) |  | TMM | 2023 |
| TGFuse  | Tgfuse: An infrared and visible image fusion approach based on transformer and generative adversarial network | [Paper](https://ieeexplore.ieee.org/abstract/document/10122870) | [Code](https://github.com/dongyuya/TGFuse) | TIP | 2023 |
| TIMFusion | A task-guided, implicitlysearched and metainitialized deep model for image fusion | [Paper](https://ieeexplore.ieee.org/abstract/document/10480582) | [Code](https://github.com/LiuZhu-CV/TIMFusion) | TPAMI | 2024 |
| TarDAL | Target-aware dual adversarial learning and a multi-scenario multimodality benchmark to fuse infrared and visible for object detection | [Paper](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Target-Aware_Dual_Adversarial_Learning_and_a_Multi-Scenario_Multi-Modality_Benchmark_To_CVPR_2022_paper.html) | [Code](https://github.com/dlut-dimt/TarDAL) | CVPR | 2022 |
| Text-IF | Text-if: Leveraging semantic text guidance for degradation-aware and interactive image fusion | [Paper](https://openaccess.thecvf.com/content/CVPR2024/html/Yi_Text-IF_Leveraging_Semantic_Text_Guidance_for_Degradation-Aware_and_Interactive_Image_CVPR_2024_paper.html) | [Code](https://github.com/XunpengYi/Text-IF) | CVPR | 2024 |
| U2Fusion | U2fusion: A unified unsupervised image fusion network | [Paper](https://ieeexplore.ieee.org/abstract/document/9151265) | [Code](https://github.com/hanna-xu/U2Fusion) | TPAMI | 2020 |
| UMFusion | Unsupervised misaligned infrared and visible image fusion via cross-modality image generation and registration | [Paper](https://arxiv.org/abs/2205.11876) | [Code](https://github.com/wdhudiekou/UMF-CMGR) | IJCAI | 2022 |
| UMIR | Unsupervised multi-modal image registration via geometry preserving image-to-image translation | [Paper](https://openaccess.thecvf.com/content_CVPR_2020/html/Arar_Unsupervised_Multi-Modal_Image_Registration_via_Geometry_Preserving_Image-to-Image_Translation_CVPR_2020_paper.html) |  | CVPR | 2020 |
| YDTR | Ydtr: Infrared and visible image fusion via y-shape dynamic transformer | [Paper](https://ieeexplore.ieee.org/abstract/document/9834137) | [Code](https://github.com/tthinking/YDTR) | TMM | 2022 |
